{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f16e9685-d891-4de1-9a24-86b58361570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "542d8071-14cd-440d-b0d0-cfea6b4ff616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "636a8924-3543-4f04-b698-390b27b4d3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        './train',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e563973a-f9d7-41bf-a20f-b01903d3e926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "        './val',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc895f7d-2f97-45f8-861b-0f5e4fba45be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 74, 74, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 72, 72, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 36, 36, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 41472)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               5308544   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,319,978\n",
      "Trainable params: 5,319,978\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.2156 - accuracy: 0.5340"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nFileNotFoundError: [Errno 2] No such file or directory: './val\\\\Tomato___Spider_mites Two-spotted_spider_mite\\\\Tomato___Spider_mites Two-spotted_spider_mite_original_00fa99e8-2605-4d72-be69-98277587d84b___Com.G_SpM_FL 1453.JPG_7869a40f-45b5-4912-b358-2bcc41d5322c.JPG'\nTraceback (most recent call last):\n\n  File \"C:\\Users\\cmbub\\OneDrive\\Desktop\\python\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\cmbub\\OneDrive\\Desktop\\python\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\cmbub\\OneDrive\\Desktop\\python\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1004, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\cmbub\\OneDrive\\Desktop\\python\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 830, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\cmbub\\OneDrive\\Desktop\\python\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 956, in generator_fn\n    yield x[i]\n\n  File \"C:\\Users\\cmbub\\OneDrive\\Desktop\\python\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"C:\\Users\\cmbub\\OneDrive\\Desktop\\python\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 227, in _get_batches_of_transformed_samples\n    img = load_img(filepaths[j],\n\n  File \"C:\\Users\\cmbub\\OneDrive\\Desktop\\python\\lib\\site-packages\\keras_preprocessing\\image\\utils.py\", line 113, in load_img\n    with open(path, 'rb') as f:\n\nFileNotFoundError: [Errno 2] No such file or directory: './val\\\\Tomato___Spider_mites Two-spotted_spider_mite\\\\Tomato___Spider_mites Two-spotted_spider_mite_original_00fa99e8-2605-4d72-be69-98277587d84b___Com.G_SpM_FL 1453.JPG_7869a40f-45b5-4912-b358-2bcc41d5322c.JPG'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_test_function_2407]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 31>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m cnn\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Fit\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m temp \u001b[38;5;241m=\u001b[39m \u001b[43mcnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\python\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnknownError\u001b[0m: Graph execution error:\n\nFileNotFoundError: [Errno 2] No such file or directory: './val\\\\Tomato___Spider_mites Two-spotted_spider_mite\\\\Tomato___Spider_mites Two-spotted_spider_mite_original_00fa99e8-2605-4d72-be69-98277587d84b___Com.G_SpM_FL 1453.JPG_7869a40f-45b5-4912-b358-2bcc41d5322c.JPG'\nTraceback (most recent call last):\n\n  File \"C:\\Users\\cmbub\\OneDrive\\Desktop\\python\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\cmbub\\OneDrive\\Desktop\\python\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\cmbub\\OneDrive\\Desktop\\python\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1004, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\cmbub\\OneDrive\\Desktop\\python\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 830, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\cmbub\\OneDrive\\Desktop\\python\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 956, in generator_fn\n    yield x[i]\n\n  File \"C:\\Users\\cmbub\\OneDrive\\Desktop\\python\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"C:\\Users\\cmbub\\OneDrive\\Desktop\\python\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 227, in _get_batches_of_transformed_samples\n    img = load_img(filepaths[j],\n\n  File \"C:\\Users\\cmbub\\OneDrive\\Desktop\\python\\lib\\site-packages\\keras_preprocessing\\image\\utils.py\", line 113, in load_img\n    with open(path, 'rb') as f:\n\nFileNotFoundError: [Errno 2] No such file or directory: './val\\\\Tomato___Spider_mites Two-spotted_spider_mite\\\\Tomato___Spider_mites Two-spotted_spider_mite_original_00fa99e8-2605-4d72-be69-98277587d84b___Com.G_SpM_FL 1453.JPG_7869a40f-45b5-4912-b358-2bcc41d5322c.JPG'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_test_function_2407]"
     ]
    }
   ],
   "source": [
    "cnn = tf.keras.models.Sequential()\n",
    "\n",
    "#Convolution layer 1\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size = 3, activation='relu',input_shape=[150, 150,3]))\n",
    "\n",
    "# Pooling 1\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "#Convolution layer 2\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size = 3, activation='relu',input_shape=[150, 150,3]))\n",
    "\n",
    "# Pooling 2\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# Flattening\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "\n",
    "#Full Conncetion\n",
    "cnn.add(tf.keras.layers.Dense(units=128,activation='relu'))\n",
    "\n",
    "#Output Layer\n",
    "cnn.add(tf.keras.layers.Dense(units=10,activation='softmax'))\n",
    "\n",
    "#Compiling\n",
    "cnn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "cnn.summary()\n",
    "\n",
    "# Fit\n",
    "temp = cnn.fit(x = train_generator, validation_data=test_generator,epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac06623-adf7-434e-bed1-3a7bd48c356b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
